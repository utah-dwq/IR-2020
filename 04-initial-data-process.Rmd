# Initial data processing {#init-process}

## Data validation
Functions to update & apply data validation tables, generate data with consistent nomenclature.  
1. Labs & activity types  
2. Activity media  
3. Parameter names & fractions  
4. Detection conditions  
5. Detection limit types  
6. Unit conversion factors  
7. Apply screening tables and subset to accepted data  

### Update screening/translation tables
#### Read initial site review and reject data from auto-rejected sites before updating
```{r, eval=F}
sites_auto_val=as.data.frame(readxl::read_excel('P:/WQ/Integrated Report/IR_2020/2020-IR-assessments/assessment/02_site_validation/site-reviews-Jake-2019-08-02 2 ready for other reviews.xlsx', 'sites'))
mlids=sites_auto_val$MonitoringLocationIdentifier[sites_auto_val$IR_FLAG!='REJECT']
update_table_data=irdata$merged_results[irdata$merged_results$MonitoringLocationIdentifier %in% mlids,]
```

#### Update detection condition / limit name tables
```{r, update-detcondlim, eval=F}
updateDetCondLimTables(results=update_table_data, detquantlim=irdata$detquantlim, translation_wb=translation_wb,
						detConditionTable_startRow=3, detLimitTypeTable_startRow=3)
```

#### Update lab/activity & media tables
```{r, labactmedia, eval=F}
updateLabActMediaTables(update_table_data, translation_wb=translation_wb, labNameActivityTable_startRow = 2)
```

#### Update parameter translation tables
```{r, update-param-trans, eval=F}
updateParamTrans(data=update_table_data, detquantlim=irdata$detquantlim,  translation_wb=translation_wb, WQPParamCASID_startRow = 4)
```

### Add Salt Lake County Data from Portal
Salt Lake County field parameters did not make it into the WQP before the end of the call for data. We performed the preliminary assessments and secondary reviews without the SLCo data, but these data were since pulled, run through the site auto-validation, used to update the translation workbook, and at this point will be added to the rest of the data for subsequent data processing steps. For more documentation on the actions taken with the SLCo data, see the Salt Lake County Data Download section.

SLCo data were used to create the updated translation workbook, which also contains the updated master site list.

**Update 6/24/20** We decided to halt all assessments involving SLCo data due to data duplication and upload issues. These sections of the programming will not be run for the draft IR.

#### Read in SLCo Data
```{r, eval=FALSE, upload-slco}
# slcodata <- readWQPFiles(file_select=FALSE,
#             narrowresult_file = "09_SLCOdata\\01_raw_data\\narrowresult-2019-10-22-spec-chars-filled.csv",
#             sites_file = "09_SLCOdata\\01_raw_data\\sites-2019-10-22.csv",
#             activity_file = "09_SLCOdata\\01_raw_data\\activity-2019-10-22.csv",
#             detquantlim_file = "09_SLCOdata\\01_raw_data\\detquantlim-2019-10-22.csv",
#             orph_check = TRUE)
# objects(slcodata)
```

#### Append SLCo Data to rest of IR Data
```{r, eval = FALSE,add-slco}
# irdata$merged_results = plyr::rbind.fill(irdata$merged_results, slcodata$merged_results)
```

#### Reject Records from Secondary Reviews

```{r, eval=FALSE, rejection-files}
awqms_rejections = as.data.frame(readxl::read_excel('08_secondary_reviews/COMPILED REJECTIONS/AWQMS_rejections_RSP_v2.xlsx', 'record-reviews'))
blmmoab_rejections = as.data.frame(readxl::read_excel('08_secondary_reviews/COMPILED REJECTIONS/BLM_MOAB_DO_rejections.xlsx', 'record-reviews'))
crazytempphdo_rejections = as.data.frame(readxl::read_excel('08_secondary_reviews/COMPILED REJECTIONS/crazy_ph_temp_do_values_rejection_template_V2.xlsx', 'record-reviews'))
flowrev_rejections = as.data.frame(readxl::read_excel('08_secondary_reviews/COMPILED REJECTIONS/flow_review_rejections_by_resultidentifier_v2.xlsx', 'record-reviews'))
labactcomment_rejections = as.data.frame(readxl::read_excel('08_secondary_reviews/COMPILED REJECTIONS/records_to_reject_lab_activity_comments.xlsx', 'record-reviews'))
secondaryrev_rejections = as.data.frame(readxl::read_excel('08_secondary_reviews/COMPILED REJECTIONS/rejections_secondary_reviews.xlsx', 'record-reviews'))
secondaryrev_rejections$ActivityStartDate[4] = "2018-05-29"
secondaryrev_rejections$ActivityStartDate = as.POSIXct(secondaryrev_rejections$ActivityStartDate)

all_record_rejections = plyr::rbind.fill(awqms_rejections, blmmoab_rejections, crazytempphdo_rejections, flowrev_rejections, labactcomment_rejections, secondaryrev_rejections)

save(all_record_rejections, file = "secondary_review_record_rejections.RData")

rm(awqms_rejections, blmmoab_rejections, crazytempphdo_rejections, flowrev_rejections, labactcomment_rejections, secondaryrev_rejections)
```

#### Incorporate AU Resegmentation into the master site tab of the translation workbook
This R code chunk documents the process taken to update the master site file list in the translation workbook following AU resegmentation finalization. It does not need to be run unless changes are made to AU's, and the sites need to be re-assigned.
```{r, eval = F}
sites = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\IR-2020\\ir_translation_workbook_working_v13_eh - no IR_Fraction formula.xlsx", sheet = "masterSiteTable")
names(sites)[names(sites)=="ASSESS_ID"] = "ASSESS_ID2016"
names(sites)[names(sites)=="AU_NAME"] = "AU_NAME2016"
names(sites)[names(sites)=="AU_Type"] = "AU_Type2016"

sites_acc = subset(sites, sites$IR_FLAG=="ACCEPT") #&!sites$AU_NAME2016%in%c("Lake Powell"))
sites_rej = subset(sites, sites$IR_FLAG=="REJECT") #&!sites$AU_NAME2016%in%c("Lake Powell"))
sites_accnew = wqTools::assignAUs(data = sites_acc, lat = "IR_Lat", long = "IR_Long")
sites_rejnew = wqTools::assignAUs(data = sites_rej, lat = "LatitudeMeasure", long = "LongitudeMeasure")

sites_all = plyr::rbind.fill(sites_accnew, sites_rejnew)
sites_all$ASSESS_ID = ifelse(is.na(sites_all$ASSESS_ID),sites_all$ASSESS_ID2016, sites_all$ASSESS_ID)
sites_all$AU_NAME = ifelse(is.na(sites_all$AU_NAME),sites_all$AU_NAME2016, sites_all$AU_NAME)
sites_all$AU_Type = ifelse(is.na(sites_all$AU_Type),sites_all$AU_Type2016, sites_all$AU_Type)
sites_all$different = ifelse(sites_all$ASSESS_ID==sites_all$ASSESS_ID2016, 0, 1)
write.csv(sites_all, "new_master_site_file_aureseg.csv", row.names = FALSE) # copied and pasted into master site sheet in translation workbook.

### Check
# acc_sites_reseg = subset(sites_all, sites_all$IR_FLAG=="ACCEPT"&sites_all$different==1)
# au_reseg = readxl::read_xlsx("C:\\Users\\ehinman\\Downloads\\site_au_reseg (2).xlsx", sheet ="Resgement sites")
# au_reseg = au_reseg[,!names(au_reseg)%in%c("IR_Lat","IR_Long")]
# 
# merged_check = merge(acc_sites_reseg, au_reseg, all = TRUE)
# write.csv(merged_check, "au_reseg_site_check.csv", row.names = FALSE)
```

### Load data objects for processing
```{r, load-rdata}
load("irdata_wqp_raw.Rdata")
load("secondary_review_record_rejections.RData")
```

```{r, secondary-review-rejections}
resultids_reject = as.character(unique(all_record_rejections$ResultIdentifier))

secondary_review_rejected_records = subset(irdata$merged_results, irdata$merged_results$ResultIdentifier%in%resultids_reject)
secondary_review_rejected_records$IR_SecondaryReview_FLAG = "REJECT"
secondary_review_rejected_records$IR_SecondaryReview_COMMENT = "Determined inappropriate for IR assessment due to data concerns contained in Appendix 3 of the IR Assessment Methods"

merged_results = subset(irdata$merged_results, !(irdata$merged_results$ResultIdentifier%in%resultids_reject))
```

```{r, echo = FALSE}
dim(merged_results) # 1351187
dim(irdata$merged_results) #1362335
length(resultids_reject)+dim(merged_results)[1]# 1362377
length(resultids_reject[!(resultids_reject%in%irdata$merged_results$ResultIdentifier)]) #42, likely SLCOWs ResultIdentifiers
rm(resultids_reject)
rm(all_record_rejections)
```


### Apply pre-lim screening tables
1. Sites
2. Activity media
3. Lab/activity

```{r, apply-screens}
translation_wb='ir_translation_workbook_working_v15_eh_resegmented - no IR_Fraction formula.xlsx'
merged_results_flagged=merged_results %>%
	applyScreenTable(wb=translation_wb, sheetname="masterSiteTable", startRow=1, flag_col_name="IR_Site_FLAG", com_col_name="IR_Site_COMMENT")
rej_data=subset(merged_results_flagged, IR_Site_FLAG=='REJECT')
acc_data=subset(merged_results_flagged, IR_Site_FLAG=='ACCEPT')

(subset(acc_data, MonitoringLocationIdentifier=='UTAHDWQ_WQX-5916570' & CharacteristicName=='Magnesium'))


acc_data=acc_data%>% 
	applyScreenTable(wb=translation_wb, sheetname="activityMediaNameTable", startRow=1, flag_col_name="IR_ActMedia_FLAG", com_col_name="IR_ActMedia_COMMENT") %>% 
	applyScreenTable(wb=translation_wb, sheetname="labNameActivityTable", startRow=3, flag_col_name="IR_LabAct_FLAG", com_col_name="IR_LabAct_COMMENT") %>% 
	applyScreenTable(wb=translation_wb, sheetname="detConditionTable", startRow=3, flag_col_name="IR_DetCond_FLAG", com_col_name="IR_DetCond_COMMENT")


with(acc_data,{table(ActivityMediaName, IR_ActMedia_FLAG)})
rej_data_flag=subset(acc_data, IR_Site_FLAG=='REJECT' | IR_ActMedia_FLAG=='REJECT' | IR_LabAct_FLAG=='REJECT' | IR_DetCond_FLAG=='REJECT')
rej_data=plyr::rbind.fill(rej_data, rej_data_flag)
acc_data=subset(acc_data, IR_Site_FLAG=='ACCEPT' & IR_ActMedia_FLAG=='ACCEPT' & (IR_LabAct_FLAG=='ACCEPT' |  IR_LabAct_FLAG=='REVIEW') & IR_DetCond_FLAG=='ACCEPT')

```

```{r, echo = FALSE}
rm(rej_data_flag)
rm(merged_results)
```


### Determine detection conditions and fill NDs
```{r, fill-masked}
acc_data=fillMaskedValues(results=acc_data, detquantlim=irdata$detquantlim, translation_wb=translation_wb,
									   detLimitTypeTable_sheetname="detLimitTypeTable", detLimitTypeTable_startRow=3,
									   unitConvTable_sheetname="unitConvTable", unitConvTable_startRow=1, unitConvTable_startCol=1,
									   lql_fac=0.5, uql_fac=1)
```

### Back-fill units for data where unit was NA in data, but existed in detquantlim - add records w/o units in either to rejection dataframe
```{r, fill-units}
table(is.na(acc_data$ResultMeasure.MeasureUnitCode))
acc_data=within(acc_data, {
	ResultMeasure.MeasureUnitCode=ifelse(is.na(ResultMeasure.MeasureUnitCode) & !is.na(IR_Unit), as.character(IR_Unit), as.character(ResultMeasure.MeasureUnitCode))
	IR_Unit_FLAG=ifelse(!is.na(ResultMeasure.MeasureUnitCode), 'ACCEPT', 'REJECT')
	IR_Unit_Comment=ifelse(IR_Unit_FLAG=='ACCEPT', NA, 'No units available for data point')
})
table(acc_data$ResultMeasure.MeasureUnitCode)
table(is.na(acc_data$ResultMeasure.MeasureUnitCode))
any(acc_data$CharacteristicName =='Bis2-Chloroisopropy1Ether')
unit_rej_data=subset(acc_data, IR_Unit_FLAG!='ACCEPT')
rej_data=plyr::rbind.fill(rej_data, unit_rej_data)
acc_data=subset(acc_data, IR_Unit_FLAG=='ACCEPT')
rm(unit_rej_data)
```

### Apply parameter translation table
```{r, param-trans}
acc_data=applyScreenTable(acc_data, wb=translation_wb, sheetname="paramTransTable", startRow=4, flag_col_name="IR_Parameter_FLAG", com_col_name="IR_Parameter_COMMENT")
table(acc_data$IR_Parameter_FLAG, exclude=NULL)

```

### Rejecting data via parameter table, rbind rejected data to rej_data object

```{r, rej-param}
param_rej_data=subset(acc_data, IR_Parameter_FLAG=='REJECT')
rej_data=plyr::rbind.fill(rej_data, param_rej_data)
acc_data=subset(acc_data, IR_Parameter_FLAG=='ACCEPT' | IR_Parameter_FLAG=='REVIEW')
rm(param_rej_data)
table(acc_data$ResultSampleFractionText, acc_data$IR_Fraction, exclude=NULL)
# dim(acc_data)
# dim(rej_data)
# dim(merged_results)

table(is.na(acc_data$CAS))
```

#### Removal of AU-parameter combinations associated with SLCo data
In the secondary review process, we found an uploading issue with SLCo data submitted by DWQ as a cooperator, and SLCo data submitted to the Water Quality Portal. There were discrepancies in the parameters uploaded, but also a range of records with (almost, but not entirely) duplicated values. It was unclear which records were the true records to keep for assessment, so we determined the best way forward is to defer ALL assessments of parameters for which there is SLCo-submitted OR DWQ-submitted data to the next cycle. Below is the step to remove all data associated with this effort.
```{r, echo = FALSE, eval = FALSE}
# au_param_rej=as.data.frame(readxl::read_excel('P:/WQ/Integrated Report/IR_2020/2020-IR-assessments/assessment/08_secondary_reviews/COMPILED REJECTIONS/AU_param_rejections_SLCo_data_discrepancies_v2.xlsx', 'au-reviews'))
# save(au_param_rej, file = "au_parameter_rejections_slco.RData")
```

```{r, remove-slco-asmts}
load("au_parameter_rejections_slco.RData")
names(au_param_rej)[names(au_param_rej)=="ASSESS_ID"] = "ASSESS_ID2016"
au_param_rej$SLCo_flag = "REJECT"
au_param_rej$SLCo_comment = au_param_rej$Comment
au_param_rej = au_param_rej[,!names(au_param_rej)%in%c("Reviewer","Comment","ReviewDate")]

acc_slco_merge = merge(acc_data, au_param_rej, all.x = TRUE)
slco_rej_data = subset(acc_slco_merge, acc_slco_merge$SLCo_flag=="REJECT")
rej_data = plyr::rbind.fill(rej_data, slco_rej_data)
acc_data = subset(acc_slco_merge, is.na(acc_slco_merge$SLCo_flag))
acc_data = acc_data[,!names(acc_data)%in%c("SLCo_flag","SLCo_comment", "slco","dwq")]

dim(acc_data)[1]+dim(slco_rej_data)[1]==dim(acc_slco_merge)[1]

screened_data=rej_data
```

```{r, echo=F}
# COUNT CHECK
if(!(dim(screened_data)[1]+dim(acc_data)[1]==dim(merged_results_flagged)[1])){
  warning("Rejected and accepted records do not match total record count before applying screen tables.")
}
rm(rej_data)
```

### Assign criteria and track which data do not have criteria
```{r, assign-crit}
memory.limit(size=56000)
acc_data_criteria=assignCriteria(acc_data, crit_wb='IR_uses_standards_working_v6_eh.xlsx', crit_sheetname='criteria', ss_sheetname='ss_criteria',
  crit_startRow = 3, ss_startRow = 4, rm_nocrit = TRUE, print = TRUE)

acc_data_nocrit = subset(acc_data, !(acc_data$ResultIdentifier%in%acc_data_criteria$ResultIdentifier))

acc_data_nocrit$IR_Criteria_FLAG = "NOT ASSESSED"
acc_data_nocrit$IR_Criteria_COMMENT = "No criteria to assess."
```

```{r, echo=FALSE}
if(!(length(unique(acc_data$ResultIdentifier))-length(unique(acc_data_criteria$ResultIdentifier))==length(unique(acc_data_nocrit$ResultIdentifier)))){
  warning("Record counts do not match before/after assigning criteria.")
}

```

### Update unit conversion table
```{r, update-uct, eval=FALSE}
updateUnitConvTable(acc_data_criteria, translation_wb=translation_wb)
```

### Data prep
```{r, data-prep}
prepped_data=dataPrep(data=acc_data_criteria, translation_wb=translation_wb, cf_formulas_sheetname="cf_formulas", crit_wb="IR_uses_standards_working_v6_eh.xlsx", startRow_formulas=3)
objects(prepped_data)
```

```{r, echo = F}
## CHECK THAT ALL DROPPED RECORDS ARE PROFILE RECORDS ASSESSED ELSEWHERE
# 126329 profs
length(unique(acc_data_criteria$ResultIdentifier)) #592766
length(unique(c(prepped_data$rej_data_reasons$ResultIdentifier, prepped_data$acc_data$ResultIdentifier))) #466437

```

### Aggregate all rejected records from screening and data prep process

```{r}
rej_dataprep = prepped_data$rej_data_reasons
rej_dataprep$IR_DataPrep_FLAG = "REJECT"
names(rej_dataprep)[names(rej_dataprep)=="reason"]="IR_DataPrep_Comment"

all_rejected_records = plyr::rbind.fill(screened_data, rej_dataprep, secondary_review_rejected_records, acc_data_nocrit)

save(all_rejected_records, screened_data, rej_dataprep, secondary_review_rejected_records, acc_data_nocrit, file = "all_rejected_data_objects.RData")
rm(screened_data, rej_dataprep, secondary_review_rejected_records, acc_data_nocrit)
```

```{r, echo = FALSE}
## CHECKS
irids = length(unique(irdata$merged_results$ResultIdentifier))
aftids = length(unique(c(all_rejected_records$ResultIdentifier, prepped_data$acc_data$ResultIdentifier)))

irids - aftids #126329, same number of profile resids removed in dataprep
```
