location = wqTools::assignPolys("wmu_poly", columns = "Mgmt_Unit",data=location, lat = "Project.Latitude", long = "Project.Longitude")
data = merge(data, location, all.x = TRUE)
View(data)
data = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase\\NPS_projects_draft_JB.xlsx")
colnames(data) = gsub(" ", ".", colnames(data))
data$Year.Awarded = paste0(as.character(data$Year.Awarded),"-01-01")
data$Year.Awarded = as.Date(data$Year.Awarded, format = "%Y-%m-%d")
location = na.omit(unique(data[,c("Project.Latitude","Project.Longitude")]))
location = wqTools::assignPolys("wmu_poly", columns = "Mgmt_Unit",data=location, lat = "Project.Latitude", long = "Project.Longitude")
data = merge(data, location, all.x = TRUE)
View(data)
data = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase\\NPS_projects_draft_JB.xlsx")
colnames(data) = gsub(" ", ".", colnames(data))
data$Year.Awarded = paste0(as.character(data$Year.Awarded),"-01-01")
data$Year.Awarded = as.Date(data$Year.Awarded, format = "%Y-%m-%d")
location = na.omit(unique(data[,c("Project.Latitude","Project.Longitude")]))
location = wqTools::assignPolys("wmu_poly", columns = "Mgmt_Unit",data=location, lat = "Project.Latitude", long = "Project.Longitude")
data = merge(data, location, all.x = TRUE)
data$Mgmt_Unit[data$Watershed=="Statewide"] = "Statewide"
data$Mgmt_Unit[is.na(data$Mgmt_Unit)] = "No Location Available"
data$Mgmt_Unit = as.character(data$Mgmt_Unit)
data$Project.Latitude[data$Mgmt_Unit=="No Location Available"] = jitter(41.979736, factor = 0.01)
data$Project.Longitude[data$Mgmt_Unit=="No Location Available"] = jitter(-114.014642, factor = 0.01)
data$Project.Latitude[data$Mgmt_Unit=="Statewide"] = jitter(39.419220, factor = 0.01)
data$Project.Longitude[data$Mgmt_Unit=="Statewide"] = jitter(-111.950684, factor = 0.01)
data$Project.Type = as.factor(data$Project.Type)
data = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase\\NPS_projects_draft_JB.xlsx")
colnames(data) = gsub(" ", ".", colnames(data))
data$Year.Awarded = paste0(as.character(data$Year.Awarded),"-01-01")
data$Year.Awarded = as.Date(data$Year.Awarded, format = "%Y-%m-%d")
location = na.omit(unique(data[,c("Project.Latitude","Project.Longitude")]))
location = wqTools::assignPolys("wmu_poly", columns = "Mgmt_Unit",data=location, lat = "Project.Latitude", long = "Project.Longitude")
data = merge(data, location, all.x = TRUE)
data$Mgmt_Unit = as.character(data$Mgmt_Unit)
data$Mgmt_Unit[data$Watershed=="Statewide"] = "Statewide"
data$Mgmt_Unit[is.na(data$Mgmt_Unit)] = "No Location Available"
data$Project.Latitude[data$Mgmt_Unit=="No Location Available"] = jitter(41.979736, factor = 0.01)
data$Project.Longitude[data$Mgmt_Unit=="No Location Available"] = jitter(-114.014642, factor = 0.01)
data$Project.Latitude[data$Mgmt_Unit=="Statewide"] = jitter(39.419220, factor = 0.01)
data$Project.Longitude[data$Mgmt_Unit=="Statewide"] = jitter(-111.950684, factor = 0.01)
data$Project.Type = as.factor(data$Project.Type)
View(data)
str(data$Amount.Awarded)
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
data = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase\\NPS_projects_draft_JB.xlsx")
colnames(data) = gsub(" ", ".", colnames(data))
data$Year.Awarded = paste0(as.character(data$Year.Awarded),"-01-01")
data$Year.Awarded = as.Date(data$Year.Awarded, format = "%Y-%m-%d")
location = na.omit(unique(data[,c("Project.Latitude","Project.Longitude")]))
location = wqTools::assignPolys("wmu_poly", columns = "Mgmt_Unit",data=location, lat = "Project.Latitude", long = "Project.Longitude")
data = merge(data, location, all.x = TRUE)
data$Mgmt_Unit = as.character(data$Mgmt_Unit)
data$Mgmt_Unit[data$Watershed=="Statewide"] = "Statewide"
data$Mgmt_Unit[is.na(data$Mgmt_Unit)] = "No Location Available"
data$Project.Latitude[data$Mgmt_Unit=="No Location Available"]
data$Project.Longitude[data$Mgmt_Unit=="No Location Available"]
runApp('GitHub/NPS_Project_Database/NPSDatabase')
jitter(rep(41.979736, 10), factor = 0.01)
data = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase\\NPS_projects_draft_JB.xlsx")
colnames(data) = gsub(" ", ".", colnames(data))
data$Year.Awarded = paste0(as.character(data$Year.Awarded),"-01-01")
data$Year.Awarded = as.Date(data$Year.Awarded, format = "%Y-%m-%d")
location = na.omit(unique(data[,c("Project.Latitude","Project.Longitude")]))
location = wqTools::assignPolys("wmu_poly", columns = "Mgmt_Unit",data=location, lat = "Project.Latitude", long = "Project.Longitude")
data = merge(data, location, all.x = TRUE)
data$Mgmt_Unit = as.character(data$Mgmt_Unit)
data$Mgmt_Unit[data$Watershed=="Statewide"] = "Statewide"
data$Mgmt_Unit[is.na(data$Mgmt_Unit)] = "No Location Available"
data$Project.Latitude[data$Mgmt_Unit=="No Location Available"] = jitter(rep(41.979736, length(data$Project.Latitude[data$Mgmt_Unit=="No Location Available"])), factor = 0.01)
data$Project.Longitude[data$Mgmt_Unit=="No Location Available"] = jitter(rep(-114.014642, length(data$Project.Longitude[data$Mgmt_Unit=="No Location Available"])), factor = 0.01)
data$Project.Latitude[data$Mgmt_Unit=="Statewide"] = jitter(rep(39.419220, length(data$Project.Latitude[data$Mgmt_Unit=="Statewide"])), factor = 0.01)
data$Project.Longitude[data$Mgmt_Unit=="Statewide"] = jitter(rep(-111.950684, length(data$Project.Longitude[data$Mgmt_Unit=="Statewide"])), factor = 0.01)
data$Project.Type = as.factor(data$Project.Type)
View(data)
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
type_pal = colorFactor("Spectral", data$Project.Type)
type_pall
type_pal
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
min(data$Project.Latitude)
View(data)
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
View(data)
runApp('GitHub/NPS_Project_Database/NPSDatabase')
pdat = data
labs <- lapply(seq(nrow(pdat)), function(i) {
paste0("Name: ",pdat[i,"Project.Title"],"<br>",
"Year Awarded: ",pdat[i, "Year.Awarded"],"<br>",
"Amount Awarded: $",pdat[i, "Amount.Awarded"])
})
View(labs)
library(htmltools)
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
irTools::asmntDashboard()
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
View(pdat)
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
is.na(pdat$Project.Title)
pdat$Project.Title[is.na(pdat$Project.Title)]
site_click = list()
site_click$id = "Delin Roundy Stream Bank"
site_click$lat = 37.9281
site_click$long = -112.4234
siteid=site_click$id
lat = unique(pdat[pdat$Project.Title == siteid,'Project.Latitude'])
lat = round(as.numeric(paste(lat[1,])[1]),4)
lat
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
shiny::runApp('GitHub/NPS_Project_Database/NPSDatabase')
rsconnect::deployApp("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase", account="udwq", appName="NPSTool")
shiny::runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
rsconnect::deployApp("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase", account="udwq", appName="NPSTool")
library(readxl)
library(shiny)
library(leaflet)
library(wqTools)
library(shinycssloaders)
library(shinyjs)
library(htmltools)
library(lubridate)
library(DT)
data = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase\\NPS_projects_draft_JB.xlsx")
data = readxl::read_xlsx("C:\\Users\\ehinman\\Documents\\GitHub\\NPS_Project_Database\\NPSDatabase\\data\\NPS_projects_draft_JB.xlsx")
colnames(data) = gsub(" ", ".", colnames(data))
data$Year.Awarded = paste0(as.character(data$Year.Awarded),"-01-01")
data$Year.Awarded = as.Date(data$Year.Awarded, format = "%Y-%m-%d")
location = na.omit(unique(data[,c("Project.Latitude","Project.Longitude")]))
location = wqTools::assignPolys("wmu_poly", columns = "Mgmt_Unit",data=location, lat = "Project.Latitude", long = "Project.Longitude")
View(location)
wqTools::au_poly
location = wqTools::assignAUs("au_poly", columns = "AU_NAME", data = location, lat = "Project.Latitude", long = "Project.Longitude")
location = wqTools::assignPolys("au_poly", columns = "AU_NAME", data = location, lat = "Project.Latitude", long = "Project.Longitude")
View(location)
data = merge(data, location, all.x = TRUE)
data$Mgmt_Unit = as.character(data$Mgmt_Unit)
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
runApp('GitHub/NPS_Project_Database/NPSDatabase')
load("C:/Users/ehinman/Desktop/IR-2020_files/prelim_asmnts_withSLCO_v3.Rdata")
library(wqTools)
library(irTools)
library(magrittr)
library(wqTools)
library(irTools)
library(magrittr)
load("input_data/irdata_wqp_raw.Rdata")
load("input_data\\irdata_wqp_raw.Rdata")
getwd()
setwd("C:\\Users\\ehinman\\Documents\\GitHub\\IR-2020")
load("input_data\\irdata_wqp_raw.Rdata")
load("irdata_wqp_raw.Rdata")
load("secondary_review_record_rejections.RData")
resultids_reject = as.character(unique(all_record_rejections$ResultIdentifier))
secondary_review_rejected_records = subset(irdata$merged_results, irdata$merged_results$ResultIdentifier%in%resultids_reject)
secondary_review_rejected_records$IR_SecondaryReview_FLAG = "REJECT"
secondary_review_rejected_records$IR_SecondaryReview_COMMENT = "Determined inappropriate for IR assessment due to data concerns contained in Appendix 3 of the IR Assessment Methods"
merged_results = subset(irdata$merged_results, !(irdata$merged_results$ResultIdentifier%in%resultids_reject))
rm(resultids_reject)
translation_wb='ir_translation_workbook_working_v13_eh - no IR_Fraction formula.xlsx'
merged_results_flagged=merged_results %>%
applyScreenTable(wb=translation_wb, sheetname="masterSiteTable", startRow=1, flag_col_name="IR_Site_FLAG", com_col_name="IR_Site_COMMENT")
rej_data=subset(merged_results_flagged, IR_Site_FLAG=='REJECT')
acc_data=subset(merged_results_flagged, IR_Site_FLAG=='ACCEPT')
(subset(acc_data, MonitoringLocationIdentifier=='UTAHDWQ_WQX-5916570' & CharacteristicName=='Magnesium'))
acc_data=acc_data%>%
applyScreenTable(wb=translation_wb, sheetname="activityMediaNameTable", startRow=1, flag_col_name="IR_ActMedia_FLAG", com_col_name="IR_ActMedia_COMMENT") %>%
applyScreenTable(wb=translation_wb, sheetname="labNameActivityTable", startRow=3, flag_col_name="IR_LabAct_FLAG", com_col_name="IR_LabAct_COMMENT") %>%
applyScreenTable(wb=translation_wb, sheetname="detConditionTable", startRow=3, flag_col_name="IR_DetCond_FLAG", com_col_name="IR_DetCond_COMMENT")
with(acc_data,{table(ActivityMediaName, IR_ActMedia_FLAG)})
rej_data_flag=subset(acc_data, IR_Site_FLAG=='REJECT' | IR_ActMedia_FLAG=='REJECT' | IR_LabAct_FLAG=='REJECT' | IR_DetCond_FLAG=='REJECT')
rej_data=plyr::rbind.fill(rej_data, rej_data_flag)
acc_data=subset(acc_data, IR_Site_FLAG=='ACCEPT' & IR_ActMedia_FLAG=='ACCEPT' & (IR_LabAct_FLAG=='ACCEPT' |  IR_LabAct_FLAG=='REVIEW') & IR_DetCond_FLAG=='ACCEPT')
rm(rej_data_flag)
View(merged_results_flagged)
rm(merged_results)
acc_data=fillMaskedValues(results=acc_data, detquantlim=irdata$detquantlim, translation_wb=translation_wb,
detLimitTypeTable_sheetname="detLimitTypeTable", detLimitTypeTable_startRow=3,
unitConvTable_sheetname="unitConvTable", unitConvTable_startRow=1, unitConvTable_startCol=1,
lql_fac=0.5, uql_fac=1)
table(is.na(acc_data$ResultMeasure.MeasureUnitCode))
acc_data=within(acc_data, {
ResultMeasure.MeasureUnitCode=ifelse(is.na(ResultMeasure.MeasureUnitCode) & !is.na(IR_Unit), as.character(IR_Unit), as.character(ResultMeasure.MeasureUnitCode))
IR_Unit_FLAG=ifelse(!is.na(ResultMeasure.MeasureUnitCode), 'ACCEPT', 'REJECT')
IR_Unit_Comment=ifelse(IR_Unit_FLAG=='ACCEPT', NA, 'No units available for data point')
})
table(acc_data$ResultMeasure.MeasureUnitCode)
table(is.na(acc_data$ResultMeasure.MeasureUnitCode))
any(acc_data$CharacteristicName =='Bis2-Chloroisopropy1Ether')
unit_rej_data=subset(acc_data, IR_Unit_FLAG!='ACCEPT')
rej_data=plyr::rbind.fill(rej_data, unit_rej_data)
acc_data=subset(acc_data, IR_Unit_FLAG=='ACCEPT')
rm(unit_rej_data)
# COUNT CHECK
dim(rej_data)[1]+dim(acc_data)[1]==dim(merged_results_flagged)[1]
acc_data=applyScreenTable(acc_data, wb=translation_wb, sheetname="paramTransTable", startRow=4, flag_col_name="IR_Parameter_FLAG", com_col_name="IR_Parameter_COMMENT")
table(acc_data$IR_Parameter_FLAG, exclude=NULL)
param_rej_data=subset(acc_data, IR_Parameter_FLAG=='REJECT')
rej_data=plyr::rbind.fill(rej_data, param_rej_data)
acc_data=subset(acc_data, IR_Parameter_FLAG=='ACCEPT' | IR_Parameter_FLAG=='REVIEW')
rm(param_rej_data)
table(acc_data$ResultSampleFractionText, acc_data$IR_Fraction, exclude=NULL)
table(acc_data$IR_Unit_FLAG)
any(acc_data$IR_Unit_FLAG=="REJECT")
if(any(acc_data$IR_Unit_FLAG=="REJECT")){
acc_data=subset(acc_data, IR_Unit_FLAG=='ACCEPT')
unit_rej_data = subset(acc_data, IR_Unit_FLAG=="REJECT")
rej_data = plyr::rbind.fill(rej_data, unit_rej_data)
}
acc_data[is.na(acc_data$IR_Unit_FLAG),]
table(is.na(acc_data$CAS))
screened_data=rej_data
# COUNT CHECK
dim(rej_data)[1]+dim(acc_data)[1]==dim(merged_results_flagged)[1]
rm(rej_data)
View(all_record_rejections)
rm(all_record_rejections)
memory.limit(size=56000)
acc_data_criteria=assignCriteria(acc_data, crit_wb='IR_uses_standards_working_v5_eh.xlsx', crit_sheetname='criteria', ss_sheetname='ss_criteria',
crit_startRow = 3, ss_startRow = 4, rm_nocrit = TRUE, print = TRUE)
acc_data_nocrit = subset(acc_data, !(acc_data$ResultIdentifier%in%acc_data_criteria$ResultIdentifier))
# COUNT CHECK
length(unique(acc_data$ResultIdentifier))-length(unique(acc_data_criteria$ResultIdentifier))==length(unique(acc_data_nocrit$ResultIdentifier))
prepped_data=dataPrep(data=acc_data_criteria, translation_wb=translation_wb, cf_formulas_sheetname="cf_formulas", crit_wb="IR_uses_standards_working_v5_eh.xlsx", startRow_formulas=3)
objects(prepped_data)
length(unique(acc_data_criteria$ResultIdentifier)) #616899
length(unique(c(prepped_data$rej_data_reasons$ResultIdentifier, prepped_data$acc_data$ResultIdentifier))) #490570
616899-490570
rej_dataprep = prepped_data$rej_data_reasons
rej_dataprep$IR_DataPrep_FLAG = "REJECT"
names(rej_dataprep)[names(rej_dataprep)=="reason"]="IR_DataPrep_Comment"
rejected_screening_dataprep = plyr::rbind.fill(screened_data, rej_dataprep, secondary_review_rejected_records, acc_data_nocrit)
irids = length(unique(irdata$merged_results$ResultIdentifier))
aftids = length(unique(c(rejected_screening_dataprep$ResultIdentifier, prepped_data$acc_data$ResultIdentifier)))
irids - aftids #126329, same number of profile resids removed in dataprep
rm(screened_data, rej_dataprep, acc_data_nocrit, secondary_review_rejected_records)
group_vars = c("IR_MLID", "IR_MLNAME", "IR_Lat", "IR_Long", "ASSESS_ID", "AU_NAME", "BeneficialUse", "BEN_CLASS",
"CAS", "IRParameterName", "TargetFraction", "R3172ParameterName", "ParameterGroupName",
"AsmntAggPeriod","AsmntAggPeriodUnit", "TableNumber","TableDescription","CriterionLabel","ParameterQualifier","SSC_MLID", "AsmntAggFun")
toxics_exc=countExceedances(prepped_data$toxics, group_vars = group_vars)
toxics_assessed=assessExcCounts(toxics_exc, min_n=4, max_exc_count=1, max_exc_count_id=0)
with(toxics_assessed, {table(R3172ParameterName, IR_Cat)})
with(toxics_assessed, {table(ParameterGroupName, IR_Cat)})
table(droplevels(prepped_data$radium$CharacteristicName))
table(prepped_data$radium$IR_DetCond)
radium_cast=reshape2::dcast(prepped_data$radium, IR_MLID+IR_MLNAME+IR_Lat+IR_Long+ASSESS_ID+AU_NAME+BeneficialUse+BEN_CLASS+CAS+IRParameterName+TargetFraction+R3172ParameterName+
ParameterGroupName+AsmntAggPeriod+AsmntAggPeriodUnit+TableDescription+CriterionLabel+ParameterQualifier+SSC_MLID+SSC_StartMon+SSC_EndMon+AsmntAggFun+ActivityStartDate~CharacteristicName, value.var='IR_Value')
any(!is.na(radium_cast$`Radium-226`) & !is.na(radium_cast$`Radium-228`))
conventionals_exc=countExceedances(prepped_data$conventionals, group_vars = group_vars)
conventionals_assessed=assessExcCounts(conventionals_exc, min_n=10, max_exc_pct=10, max_exc_count_id=1)
with(conventionals_assessed, {table(R3172ParameterName, IR_Cat)})
conventionals_assessed=subset(conventionals_assessed, R3172ParameterName!='Turbidity Increase' & !(R3172ParameterName=='Minimum Dissolved Oxygen' & (AsmntAggPeriod==1 | AsmntAggPeriod==7)))
with(conventionals_assessed, {table(droplevels(R3172ParameterName), IR_Cat)})
lake_tds_exc=countExceedances(prepped_data$lakes_tds, group_vars = group_vars)
lake_tds_assessed=assessExcCounts(lake_tds_exc, min_n=2, max_exc_pct=10, max_exc_pct_id=0)
with(lake_tds_assessed, {table(R3172ParameterName, IR_Cat)})
table(droplevels(prepped_data$agg_tds$ASSESS_ID), droplevels(prepped_data$agg_tds$AU_NAME))
mean(subset(prepped_data$agg_tds, NumericCriterion==4700)$IR_Value)
mean(subset(prepped_data$agg_tds, NumericCriterion==3800)$IR_Value)
ss_mean_tds_exc=countExceedances(prepped_data$agg_tds, group_vars = group_vars)
ss_mean_tds_assessed=assessExcCounts(ss_mean_tds_exc, min_n=10, max_exc_pct=50, max_exc_count_id=1)
ss_mean_tds_assessed
ecoli_dat_assess = prepped_data$ecoli
orig_rec = dim(ecoli_dat_assess)[1]
ecoli_dat_notassess = ecoli_dat_assess[grepl("2010",as.character(ecoli_dat_assess$ActivityStartDate)),] # ADD TO REJECTED DATA
rej_rec = dim(ecoli_dat_notassess)[1]
ecoli_dat_notassess$IR_Cat = "Not Assessed - Out of POR"
ecoli_dat_notassess$ActivityStartDate = as.character(ecoli_dat_notassess$ActivityStartDate)
ecoli_dat_assess = ecoli_dat_assess[!grepl("2010",as.character(ecoli_dat_assess$ActivityStartDate)),]
ecoli_dat_assess = droplevels(ecoli_dat_assess)
new_rec = dim(ecoli_dat_assess)[1]
new_rec+rej_rec==orig_rec
ecoli_dat_assess$IR_Value = ifelse(ecoli_dat_assess$IR_DetCond=="OD",2420,ecoli_dat_assess$IR_Value)
ecoli_dat_assess$IR_Value = ifelse(ecoli_dat_assess$IR_DetCond=="ND",1,ecoli_dat_assess$IR_Value)
assessed_ecoli = assessEColi(data = ecoli_dat_assess)
assessed_ecoli$non_assessed_data$ActivityStartDate = as.character(assessed_ecoli$non_assessed_data$ActivityStartDate)
# Combine all rejected data
assessed_ecoli$non_assessed_data = plyr::rbind.fill(assessed_ecoli$non_assessed_data, ecoli_dat_notassess)
length(unique(assessed_ecoli$assessed_data$IR_MLID)) # 951
length(unique(assessed_ecoli$dailyaggregated_data$IR_MLID)) # 951
length(unique(assessed_ecoli$ecoli_allscenario_asmnts$IR_MLID)) # 951
length(unique(assessed_ecoli$ecoli_scenario_rollup$IR_MLID)) # 951
length(unique(assessed_ecoli$ecoli_mlid_asmnts$IR_MLID)) # 951
mlids = unique(assessed_ecoli$ecoli_scenario_rollup$IR_MLID)
mlids1 = unique(assessed_ecoli$ecoli_mlid_asmnts$IR_MLID)
dropped_mlids = mlids[!mlids%in%mlids1]
reversenams = names(assessed_ecoli)
reversenams = rev(reversenams)
assessed_ecoli2 = assessed_ecoli[reversenams]
assessed_ecoli2$raw_data = NULL
require(openxlsx)
write.xlsx(assessed_ecoli2, file = paste0("ecoli_assessed_review_v4.xlsx"))
rm(mlids, mlids1, reversenams,dropped_mlids)
lake_profs_assessed=as.data.frame(readxl::read_excel('lake_profile_asmnts.xlsx', 'lake_profile_asmnts'))
# lake_profs_assessed=comb_asmnt_au
names(lake_profs_assessed)[names(lake_profs_assessed)=='au_param_Cat2020']='IR_Cat'
table(lake_profs_assessed$R3172ParameterName)
lake_profs_assessed=within(lake_profs_assessed, {
R3172ParameterName=as.character(R3172ParameterName)
R3172ParameterName[R3172ParameterName=='Dissolved oxygen (DO)']='Minimum Dissolved Oxygen'
R3172ParameterName[R3172ParameterName=='Temperature, water']='Max. Temperature'
})
prelim_asmnts=plyr::rbind.fill(conventionals_assessed,lake_tds_assessed,ss_mean_tds_assessed,toxics_assessed, assessed_ecoli$ecoli_mlid_asmnts,lake_profs_assessed[,!names(lake_profs_assessed) %in% c('PrevCat','au_param_Cat2020','pot_delist','new_listing')])
reject = data.frame(IR_MLID="UTAHDWQ_WQX-5913210",R3172ParameterName="Minimum Dissolved Oxygen",Remove = "1")
prelim_asmnts = merge(prelim_asmnts, reject, all.x = TRUE)
prelim_asmnts = subset(prelim_asmnts, is.na(prelim_asmnts$Remove))
prelim_asmnts = prelim_asmnts[,!names(prelim_asmnts)%in%c("Remove")]
load("external_assessments2020-06-27.RData") # remember to change if any changes occur to external assessments
load("external_assessments_v2.RData") # remember to change if any changes occur to external assessments
prelim_asmnts=plyr::rbind.fill(prelim_asmnts, external_asmnts)
prelim_asmnts$pol_ind=ifelse(prelim_asmnts$ParameterGroupName=='POLLUTION INDICATORS' | prelim_asmnts$R3172ParameterName=='Lakes tier II', 'Y', 'N')
prelim_asmnts$pol_ind[is.na(prelim_asmnts$pol_ind)]='N'
any(is.na(prelim_asmnts$IR_Cat))
load("au_paramter_rejections_slco.RData")
load("au_parameter_rejections_slco.RData")
au_param_rej$SLCo_flag = "REJECT"
asmt_rej_merge = merge(prelim_asmnts, au_param_rej, all.x = TRUE)
rejected_records_slco_aus = subset(asmt_rej_merge, asmt_rej_merge$SLCo_flag=="REJECT")
prelim_asmnts = subset(asmt_rej_merge, is.na(asmt_rej_merge$SLCo_flag))
prelim_asmnts = prelim_asmnts[,!names(prelim_asmnts)%in%c("SLCo_flag")]
prelim_asmnts = prelim_asmnts[,!names(prelim_asmnts)%in%c("Mgmt_Unit","AU_Type")]
wmus=unique(acc_data_criteria[,c('ASSESS_ID','AU_Type','Mgmt_Unit')])
dim(prelim_asmnts)
prelim_asmnts=merge(prelim_asmnts, wmus, all.x=T)
dim(prelim_asmnts)
prelim_asmnts$Mgmt_Unit[prelim_asmnts$BeneficialUse=='5A']='Great Salt Lake'
any(is.na(prelim_asmnts$Mgmt_Unit))
prelim_asmnts$lake=ifelse(prelim_asmnts$AU_Type=='Reservoir/Lake' | prelim_asmnts$BeneficialUse=='5A', 'Y', 'N')
table(prelim_asmnts$lake, exclude=NULL)
permits=as.data.frame(readxl::read_excel("P:/WQ/Integrated Report/IR_2020/2020-IR-assessments/assessment/08_secondary_reviews/Permits/Current UPDES permits w_WLAs.xlsx", 'permits'))
save(permits, file = "current_updes_permits.RData")
rm(permits)
load("current_updes_permits.RData")
ut_fac1=wqTools::readECHO_fac(p_st="ut", p_act="y")
fac_coords1=do.call(rbind.data.frame,ut_fac1$geometry$coordinates)
names(fac_coords1)=c("dec_long","dec_lat")
fac_coords1=data.frame(ut_fac1$properties[,c("SourceID","CWPName","CWPFacilityTypeIndicator")], (fac_coords1))
permits2=subset(permits, !PermitID %in% ut_fac1$properties$SourceID)
ut_fac2=wqTools::readECHO_fac(p_pid=permits2$PermitID)
fac_coords2=do.call(rbind.data.frame,ut_fac2$geometry$coordinates)
names(fac_coords2)=c("dec_long","dec_lat")
fac_coords2=data.frame(ut_fac2$properties[,c("SourceID","CWPName","CWPFacilityTypeIndicator")], (fac_coords2))
ut_fac=rbind(fac_coords1, fac_coords2)
names(ut_fac)[names(ut_fac)=="SourceID"]="locationID"
names(ut_fac)[names(ut_fac)=="CWPName"]="locationName"
names(ut_fac)[names(ut_fac)=="CWPFacilityTypeIndicator"]="locationType"
names(ut_fac)[names(ut_fac)=="dec_long"]="LongitudeMeasure"
names(ut_fac)[names(ut_fac)=="dec_lat"]="LatitudeMeasure"
ut_fac=wqTools::assignAUs(ut_fac)
ut_fac$priority=ifelse(ut_fac$locationID %in% permits$PermitID, 'Y', 'N')
permits_aus=subset(ut_fac, locationID %in% permits$PermitID)
prelim_asmnts$permit=ifelse(prelim_asmnts$ASSESS_ID %in% permits_aus$ASSESS_ID, 'Y','N')
table(prelim_asmnts$permit, exclude=NULL)
write.csv(file='ut_facilities.csv', ut_fac, row.names=F)
prelim_asmnts$new_listing=NA
current_listings=read.csv(file='current_listings.csv')
prelim_asmnts=merge(prelim_asmnts, current_listings, all.x=T)
prelim_asmnts$new_listing=ifelse(prelim_asmnts$pol_ind=='N' & prelim_asmnts$IR_Cat=='NS' & is.na(prelim_asmnts$AU_EPACat), 'Y', 'N')
table(prelim_asmnts$new_listing, exclude=NULL)
prelim_asmnts$confirmed_listing=ifelse(prelim_asmnts$pol_ind=='N' & prelim_asmnts$IR_Cat=='NS' & !is.na(prelim_asmnts$AU_EPACat), 'Y', 'N')
table(prelim_asmnts$confirmed_listing, exclude=NULL)
prelim_asmnts=prelim_asmnts[,!names(prelim_asmnts) %in% c('AU_EPACat','PARAM_NAME')]
site_use_param_asmnt=irTools::rollUp(list(prelim_asmnts), group_vars = c("BEN_CLASS","IR_MLID","IR_MLNAME","IR_Lat","IR_Long","ASSESS_ID","AU_NAME", "R3172ParameterName", "BeneficialUse", "pol_ind", "Mgmt_Unit","lake","permit","new_listing"), expand_uses=F)
site_use_param_asmnt=within(site_use_param_asmnt, {
site_param_review=NA
site_param_review[new_listing=='Y' & permit=='Y' & pol_ind=='N'] = 5
site_param_review[new_listing=='Y' & permit=='N' & pol_ind=='N'] = 4
site_param_review[new_listing=='N' & permit=='Y'] = 3
site_param_review[new_listing=='N' & permit=='N'  & pol_ind=='N' & AssessCat=='IDEX' & !ASSESS_ID %in% subset(site_use_param_asmnt, site_param_review %in% c('New listing, permit', 'New listing'))$ASSESS_ID] = 2
site_param_review[is.na(site_param_review)] = 1
})
table(site_use_param_asmnt$site_param_review, exclude=NULL)
au_revs=unique(site_use_param_asmnt[,c('ASSESS_ID','site_param_review')])
au_revs=aggregate(site_param_review~ASSESS_ID, au_revs, 'max')
names(au_revs)[names(au_revs)=='site_param_review']='au_rev'
site_use_param_asmnt=merge(site_use_param_asmnt, au_revs, all.x=T)
site_use_param_asmnt=within(site_use_param_asmnt, {
AU_review=NA
AU_review[au_rev==5]='New listing, permit'
AU_review[au_rev==4]='New listing'
AU_review[au_rev==3]='Permit'
AU_review[au_rev==2]='New insufficient data w/ exc'
AU_review[au_rev==1]='Review needed, low priority'
})
table(site_use_param_asmnt$AU_review, exclude=NULL)
write.csv(file='site_use_param_asmnt_v4.csv', site_use_param_asmnt, row.names=F)
rm(mlids, mlids1, reversenams,dropped_mlids, assessed_ecoli2)
# Rename some objects to make them easier to remember and use
accepted_data_flattened_criteria_dataprep = prepped_data$acc_data
data_used_in_assessments_allcolumns = subset(acc_data, acc_data$ResultIdentifier%in%unique(accepted_data_flattened_criteria_dataprep$ResultIdentifier))
grouping_columns_rollup = group_vars
lake_assessments = list(lake_tds_assessed,lake_tds_exc,lake_profs_assessed)
site_specific_tds_assessments = list(ss_mean_tds_assessed, ss_mean_tds_exc)
toxics_and_conventionals_assessments = list(conventionals_assessed, conventionals_exc, toxics_assessed, toxics_exc)
save(rejected_screening_dataprep, accepted_data_flattened_criteria, data_used_assessments_allcolumns, grouping_columns_rollup,lake_assessments, site_specific_tds_assessments, toxics_and_conventionals_assessments, prelim_asmnts, file='prelim_asmnts_v4.Rdata')
View(accepted_data_flattened_criteria_dataprep)
save(rejected_screening_dataprep, accepted_data_flattened_criteria_dataprep, data_used_assessments_allcolumns, grouping_columns_rollup,lake_assessments, site_specific_tds_assessments, toxics_and_conventionals_assessments, prelim_asmnts, file='prelim_asmnts_v4.Rdata')
save(rejected_screening_dataprep, accepted_data_flattened_criteria_dataprep, data_used_in_assessments_allcolumns, grouping_columns_rollup,lake_assessments, site_specific_tds_assessments, toxics_and_conventionals_assessments, prelim_asmnts, file='prelim_asmnts_v4.Rdata')
length(unique(accepted_data_flattened_criteria_dataprep$ResultIdentifier))
assessed_data=unique(prepped_data$acc_data[,c("CAS", "ResultIdentifier","ActivityStartDate", "IR_MLID", "IR_MLNAME", "ASSESS_ID", "AU_NAME",
"AU_Type", "BEN_CLASS", "IRParameterName", "R3172ParameterName", "IR_Value", "IR_Unit", "CriterionUnits",
"IR_DetCond", "IR_Fraction", "IR_ActivityType", "IR_Lat", "IR_Long",
"DataLoggerLine", "ActivityRelativeDepthName", "ActivityDepthHeightMeasure.MeasureValue",
"R317Descrp", "ActivityDepthHeightMeasure.MeasureUnitCode")
])
assessed_data=unique(prepped_data$acc_data[,c("CAS", "ResultIdentifier","ActivityStartDate", "IR_MLID", "IR_MLNAME", "ASSESS_ID", "AU_NAME",
"AU_Type", "BEN_CLASS", "IRParameterName", "R3172ParameterName", "IR_Value", "IR_Unit", "CriterionUnits",
"IR_DetCond", "IR_Fraction", "IR_ActivityType", "IR_Lat", "IR_Long",
"DataLoggerLine", "ActivityRelativeDepthName", "ActivityDepthHeightMeasure.MeasureValue",
"R317Descrp", "ActivityDepthHeightMeasure.MeasureUnitCode")
])
criteria=unique(prepped_data$acc_data[,c("CAS", "ActivityStartDate", "IR_MLID", "IR_MLNAME", "BeneficialUse",
"R3172ParameterName", "CriterionUnits", "TargetFraction", "CriterionLabel",
"CriterionType", "NumericCriterion","TableDescription", "ParameterQualifier",
"FrequencyCombined", "FrequencyNumber", "FrequencyUnit", "TargetActivityType")
])
criteria=subset(criteria, !BeneficialUse %in% c('CF', 'SUP'))
criteria=within(criteria, {
bu=ifelse(TableDescription=='LIST OF HUMAN HEALTH CRITERIA (CONSUMPTION)', paste0('HH-',BeneficialUse), BeneficialUse)
frac=tolower(TargetFraction)
els=ifelse(ParameterQualifier %in% c('early life stages are present','Fish Early Life Stages are Present'), 'ELS', NA)
acc_chron=ifelse(CriterionLabel =='Acute', 'acute', 'chronic')
ts=ifelse(R3172ParameterName=='Minimum Dissolved Oxygen' | R3172ParameterName=='E. coli', paste0(FrequencyNumber, ' day ', tolower(FrequencyCombined)), NA)
ts=gsub('NA day', 'daily', ts)
ts=gsub('average', 'avg', ts)
ts=gsub('minimum', 'min', ts)
label=paste(bu, R3172ParameterName, ts, els, acc_chron, frac)
label=gsub('Minimum Dissolved Oxygen', 'DO', label)
label=gsub('Max. Temperature', 'Temperature', label)
label=gsub(' NA', '', label)
label=gsub('dissolved', '(diss)', label)
label=gsub('total', '(tot)', label)
label=gsub('none', '', label)
label=gsub('daily maximum', 'max', label)
label=gsub('geometric mean', 'geomean', label)
label=ifelse(R3172ParameterName=='pH' | R3172ParameterName=='Total Dissolved Solids', paste(label, CriterionType), label)
})
criteria=within(criteria, {
bu=ifelse(TableDescription=='LIST OF HUMAN HEALTH CRITERIA (CONSUMPTION)', paste0('HH-',BeneficialUse), BeneficialUse)
frac=tolower(TargetFraction)
els=ifelse(ParameterQualifier %in% c('early life stages are present','Fish Early Life Stages are Present'), 'ELS', NA)
acc_chron=ifelse(CriterionLabel =='Acute', 'acute', 'chronic')
ts=ifelse(R3172ParameterName=='Minimum Dissolved Oxygen' | R3172ParameterName=='E. coli', paste0(FrequencyNumber, ' day ', tolower(FrequencyCombined)), NA)
ts=gsub('NA day', 'daily', ts)
ts=gsub('average', 'avg', ts)
ts=gsub('minimum', 'min', ts)
label=paste(bu, R3172ParameterName, ts, els, acc_chron, frac)
label=gsub('Minimum Dissolved Oxygen', 'DO', label)
label=gsub('Max. Temperature', 'Temperature', label)
label=gsub(' NA', '', label)
label=gsub('dissolved', '(diss)', label)
label=gsub('total', '(tot)', label)
label=gsub('none', '', label)
label=gsub('daily maximum', 'max', label)
label=gsub('geometric mean', 'geomean', label)
label=ifelse(R3172ParameterName=='pH' | R3172ParameterName=='Total Dissolved Solids', paste(label, CriterionType), label)
})
head(subset(criteria, R3172ParameterName=='Total Dissolved Solids'))
criteria=criteria[,!names(criteria) %in% c('ts','acc_chron','els','frac','bu')]
save(assessed_data, criteria, file='asmntDashboard_data_v4.Rdata')
length(prepped_data$acc_data$ResultIdentifier)
length(unique(prepped_data$acc_data$ResultIdentifier))
compiled_data = composeExport(screened_data = screened_data, prepped_data = prepped_data, toxics_assessed = toxics_assessed, conventionals_assessed = conventionals_assessed, include_rejected = FALSE, create_workbooks = FALSE)
save(compiled_data, file = 'reviewer_export_data_v4.Rdata')
View(compiled_data)
writexl::write_xlsx(list(
site_use_param_asmnt=site_use_param_asmnt,
prelim_asmnts=prelim_asmnts,
lake_prof_asmnts=lake_profs_assessed,
conventionals=subset(prepped_data$acc_data, AssessmentType=='Conventional'),
toxics=subset(prepped_data$acc_data, AssessmentType=='Toxic'),
supplement=subset(prepped_data$acc_data, AssessmentType=='All'),
ecoli=subset(prepped_data$acc_data, AssessmentType=='Ecoli')
),
path = 'prelim_asmnts_v4.xlsx', format_headers=F, col_names=T)
asmnts=read.csv(file="site_use_param_asmnt_v4.csv")
site_asmnts=irTools::rollUp(list(asmnts), group_vars=c("IR_MLID","IR_MLNAME","ASSESS_ID","AU_NAME"), cat_var="AssessCat", expand_uses=F, print=F)
names(site_asmnts)[names(site_asmnts)=="AssessCat"]="site_asmnt"
au_asmnts=irTools::rollUp(list(asmnts), group_vars=c("ASSESS_ID","AU_NAME"), cat_var="AssessCat", expand_uses=F, print=F)
names(au_asmnts)[names(au_asmnts)=="AssessCat"]="au_asmnt"
site_au_asmnts=merge(site_asmnts, au_asmnts, all.x=T)
write.csv(file="site_au_asmnts_merged.csv", site_au_asmnts, row.names=F)
save(rejected_screening_dataprep, accepted_data_flattened_criteria_dataprep, data_used_in_assessments_allcolumns, grouping_columns_rollup,lake_assessments, site_specific_tds_assessments, toxics_and_conventionals_assessments, assessed_ecoli, prelim_asmnts, file='prelim_asmnts_v4.Rdata')
View(site_use_param_asmnt)
